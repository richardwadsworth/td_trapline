{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import random, choice\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import gym\n",
    "from gym.envs.toy_text.frozen_lake import generate_random_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc = generate_random_map(size=16, p=1.0)\n",
    "env = gym.make('FrozenLake-v1', is_slippery=False, new_step_api=True, desc=desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action space =  Discrete(4)\n",
      "Observation space =  Discrete(256)\n"
     ]
    }
   ],
   "source": [
    "print(\"Action space = \", env.action_space)\n",
    "print(\"Observation space = \", env.observation_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "actionsDict = {}\n",
    "actionsDict[0] = \"  L  \"\n",
    "actionsDict[1] = \"  D  \"\n",
    "actionsDict[2] = \"  R  \"\n",
    "actionsDict[3] = \"  U  \"\n",
    "\n",
    "actionsDictInv = {}\n",
    "actionsDictInv[\"L\"] = 0\n",
    "actionsDictInv[\"D\"] = 1\n",
    "actionsDictInv[\"R\"] = 2\n",
    "actionsDictInv[\"U\"] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()\n",
    "# env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal policy:\n",
      "L/D/R   U     U     U  \n",
      "  L     -    L/R    -  \n",
      "  U     D     L     -  \n",
      "  -     R     D     !  \n"
     ]
    }
   ],
   "source": [
    "optimalPolicy = [\"L/D/R\",\"  U  \",\"  U  \",\"  U  \",\n",
    "                 \"  L  \",\"  -  \",\" L/R \",\"  -  \",\n",
    "                 \"  U  \",\"  D  \",\"  L  \",\"  -  \",\n",
    "                 \"  -  \",\"  R  \",\"  D  \",\"  !  \"]\n",
    "    \n",
    "print(\"Optimal policy:\")\n",
    "idxs = [0,4,8,12]\n",
    "for idx in idxs:\n",
    "    print(optimalPolicy[idx+0], optimalPolicy[idx+1], \n",
    "          optimalPolicy[idx+2], optimalPolicy[idx+3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def action_epsilon_greedy(q, s, epsilon=0.05):\n",
    "    if np.random.rand() > epsilon:\n",
    "        return np.argmax(q[s])\n",
    "    return np.random.randint(4)\n",
    "\n",
    "def get_action_epsilon_greedy(epsilon):\n",
    "    return lambda q,s: action_epsilon_greedy(q, s, epsilon=epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_policy(q, s):\n",
    "    return np.argmax(q[s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_performance(policy_fct, q):\n",
    "    acc_returns = 0.\n",
    "    n = 500\n",
    "    for i in range(n):\n",
    "        done, truncated = False, False\n",
    "        s = env.reset()\n",
    "        while not done and not truncated:\n",
    "            a = policy_fct(q, s)\n",
    "            (s, reward, done, truncated, info) = env.step(a)\n",
    "            acc_returns += reward\n",
    "    return acc_returns/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for sarsa(lambda)\n",
    "episodes = 8000\n",
    "STEPS = 2000\n",
    "gamma = 0.9\n",
    "\n",
    "alpha_crtic = 0.02\n",
    "alpha_actor = 0.02\n",
    "\n",
    "epsilon_start = 0.2\n",
    "epsilon_end = 0.001\n",
    "epsilon_annealing_stop = int(episodes/2)\n",
    "\n",
    "eligibility_decay = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q = np.ones((env.observation_space.n, env.action_space.n))\n",
    "# # Set q(terminal,*) equal to 0\n",
    "# q[5,:] = 0.0\n",
    "# q[7,:] = 0.0\n",
    "# q[11,:] = 0.0\n",
    "# q[12,:] = 0.0\n",
    "# q[15,:] = 0.0\n",
    "performance = np.ndarray(episodes//STEPS)\n",
    "\n",
    "\n",
    "v = np.random.rand(env.observation_space.n)\n",
    "pi = np.zeros((env.observation_space.n, env.action_space.n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to restart the Kernel. \n",
      "No debugger available, can not send 'disconnect'. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "for episode in range(episodes):\n",
    "\n",
    "    inew = min(episode,epsilon_annealing_stop)\n",
    "    epsilon = (epsilon_start * (epsilon_annealing_stop - inew) + epsilon_end * inew) / epsilon_annealing_stop\n",
    "    \n",
    "    E_actor = np.zeros((env.observation_space.n, env.action_space.n))\n",
    "    E_critic = np.zeros(env.observation_space.n)\n",
    "    \n",
    "    \n",
    "    state = env.reset()\n",
    "    action = action_epsilon_greedy(pi, state, epsilon)\n",
    "\n",
    "    while True:\n",
    "\n",
    "        (new_state, reward, done, truncated, info) = env.step(action)\n",
    "        \n",
    "        new_action = action_epsilon_greedy(pi, new_state, epsilon)\n",
    "\n",
    "        E_actor[state, action] = 1\n",
    "        \n",
    "        td_error = reward + gamma * v[new_state] - v[state]\n",
    "\n",
    "        E_critic[state] = 1\n",
    "\n",
    "        v = v + alpha_crtic * td_error * E_critic\n",
    "        E_critic = eligibility_decay * gamma * E_critic\n",
    "\n",
    "        pi = pi + alpha_actor * td_error * E_actor \n",
    "        E_actor = eligibility_decay * gamma * E_actor\n",
    "        \n",
    "        state, action = new_state, new_action\n",
    "\n",
    "        if done or truncated:\n",
    "            break\n",
    "\n",
    "    # only for plotting the performance, not part of the algorithm \n",
    "    if episode%STEPS == 0:\n",
    "        performance[episode//STEPS] = average_performance(get_action_epsilon_greedy(epsilon), q=pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Average reward of an epoch')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(STEPS*np.arange(episodes//STEPS), performance)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.title(\"Learning progress for SARSA\")\n",
    "plt.ylabel(\"Average reward of an epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greedy policy SARSA performance = 0.0\n"
     ]
    }
   ],
   "source": [
    "greedyPolicyAvgPerf = average_performance(greedy_policy, q=pi)\n",
    "print(\"Greedy policy SARSA performance =\", greedyPolicyAvgPerf) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(A,S) Value function = (256, 4)\n",
      "First row\n",
      "[[ 0.005 -0.082  0.427  0.005]\n",
      " [-0.128  0.111 -0.303 -0.109]\n",
      " [ 0.507  0.055 -0.032  0.002]\n",
      " [ 0.005  0.007  0.061  0.   ]]\n",
      "Second row\n",
      "[[-0.034 -0.055 -0.062 -0.035]\n",
      " [ 0.08   0.     0.     0.003]\n",
      " [-0.005  0.     0.     0.   ]\n",
      " [-0.01   0.     0.    -0.003]]\n",
      "Third row\n",
      "[[0.01 0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]]\n",
      "Fourth row\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "q = pi\n",
    "q = np.round(q,3)\n",
    "print(\"(A,S) Value function =\", q.shape)\n",
    "print(\"First row\")\n",
    "print(q[0:4,:])\n",
    "print(\"Second row\")\n",
    "print(q[4:8,:])\n",
    "print(\"Third row\")\n",
    "print(q[8:12,:])\n",
    "print(\"Fourth row\")\n",
    "print(q[12:16,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greedy policy found:\n",
      "  R     D     L     R  \n",
      "  L     L     D     D  \n",
      "  L     L     L     L  \n",
      "  L     L     L     !  \n",
      " \n",
      "Optimal policy:\n",
      "L/D/R   U     U     U  \n",
      "  L     -    L/R    -  \n",
      "  U     D     L     -  \n",
      "  -     R     D     !  \n"
     ]
    }
   ],
   "source": [
    "policyFound = [actionsDict[np.argmax(q[0,:])],actionsDict[np.argmax(q[1,:])],actionsDict[np.argmax(q[2,:])],actionsDict[np.argmax(q[3,:])],\n",
    "               actionsDict[np.argmax(q[4,:])],actionsDict[np.argmax(q[5,:])],actionsDict[np.argmax(q[6,:])],actionsDict[np.argmax(q[6,:])],\n",
    "               actionsDict[np.argmax(q[8,:])],actionsDict[np.argmax(q[9,:])],actionsDict[np.argmax(q[10,:])],actionsDict[np.argmax(q[11,:])],\n",
    "               actionsDict[np.argmax(q[12,:])],actionsDict[np.argmax(q[13,:])],actionsDict[np.argmax(q[14,:])],\"  !  \"]\n",
    "print(\"Greedy policy found:\")\n",
    "idxs = [0,4,8,12]\n",
    "for idx in idxs:\n",
    "    print(policyFound[idx+0], policyFound[idx+1], \n",
    "          policyFound[idx+2], policyFound[idx+3])\n",
    "\n",
    "print(\" \")\n",
    "\n",
    "print(\"Optimal policy:\")\n",
    "idxs = [0,4,8,12]\n",
    "for idx in idxs:\n",
    "    print(optimalPolicy[idx+0], optimalPolicy[idx+1], \n",
    "          optimalPolicy[idx+2], optimalPolicy[idx+3])\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "4bd624a0593993fe43ac4046b27b898fb2ef75c21c08f81e89e64ea0f51df676"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
