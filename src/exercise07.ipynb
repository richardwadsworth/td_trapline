{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import random, choice\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import gym\n",
    "from gym.envs.toy_text.frozen_lake import generate_random_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Policy(object):\n",
    "\n",
    "    def __init__(self, env) -> None:\n",
    "        self.env = env\n",
    "\n",
    "    def action(self, q, index):\n",
    "        \"\"\"\n",
    "        implement this function in the sub class\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def average_performance(self, policy_fct, q):\n",
    "    \n",
    "        acc_returns = 0.\n",
    "        n = 500\n",
    "        for i in range(n):\n",
    "            done, truncated = False, False\n",
    "            s = self.env.reset()\n",
    "            while not done and not truncated:\n",
    "                a = policy_fct(q, s)\n",
    "                s, reward, done, truncated, info = self.env.step(a)\n",
    "                acc_returns += reward\n",
    "\n",
    "        return acc_returns/n\n",
    "\n",
    "class GreedyPolicy(Policy):\n",
    "\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "\n",
    "    def action(self, q, s):\n",
    "        return np.argmax(q[s])\n",
    "\n",
    "class SoftmaxPolicy(Policy):\n",
    "    \n",
    "    def __init__(self, env, rng):\n",
    "        super().__init__(env)\n",
    "        self.rng = rng\n",
    "\n",
    "\n",
    "    def action(self, q, s, T):\n",
    "        probs = np.exp(q[s]/T) / np.sum(np.exp(q[s]/T))\n",
    "        probs =  probs/ np.sum(probs) # Ensure probs is normalised to 1 (to avoid rounding errors)\n",
    "        randchoice = self.rng.random()\n",
    "        flag = 1; k = 1\n",
    "        while flag:\n",
    "\n",
    "            if randchoice<np.sum(probs[0:k]):\n",
    "                action = k-1 # adjust for zero based action index\n",
    "                flag = 0\n",
    "            \n",
    "            k = k + 1\n",
    "\n",
    "        return action\n",
    "\n",
    "    def get_action(self, T):     \n",
    "        return lambda q,s: self.action(q, s, T=T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for sarsa(lambda)\n",
    "episodes = 2000\n",
    "STEPS = 500\n",
    "gamma = 0.9\n",
    "\n",
    "alpha_critic = 0.02\n",
    "alpha_actor = 0.02\n",
    "\n",
    "epsilon_start = 1\n",
    "epsilon_end = 0.2\n",
    "epsilon_annealing_stop = int(episodes*0.7)\n",
    "\n",
    "eligibility_decay = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action space =  Discrete(4)\n",
      "Observation space =  Discrete(256)\n",
      "Optimal policy:\n",
      "L/D/R   U     U     U  \n",
      "  L     -    L/R    -  \n",
      "  U     D     L     -  \n",
      "  -     R     D     !  \n"
     ]
    }
   ],
   "source": [
    "desc = generate_random_map(size=16, p=1.0)\n",
    "env = gym.make('FrozenLake-v1', is_slippery=False, new_step_api=True, desc=desc, max_episode_steps=STEPS)\n",
    "\n",
    "print(\"Action space = \", env.action_space)\n",
    "print(\"Observation space = \", env.observation_space)\n",
    "\n",
    "actionsDict = {}\n",
    "actionsDict[0] = \"  L  \"\n",
    "actionsDict[1] = \"  D  \"\n",
    "actionsDict[2] = \"  R  \"\n",
    "actionsDict[3] = \"  U  \"\n",
    "\n",
    "actionsDictInv = {}\n",
    "actionsDictInv[\"L\"] = 0\n",
    "actionsDictInv[\"D\"] = 1\n",
    "actionsDictInv[\"R\"] = 2\n",
    "actionsDictInv[\"U\"] = 3\n",
    "\n",
    "optimalPolicy = [\"L/D/R\",\"  U  \",\"  U  \",\"  U  \",\n",
    "                 \"  L  \",\"  -  \",\" L/R \",\"  -  \",\n",
    "                 \"  U  \",\"  D  \",\"  L  \",\"  -  \",\n",
    "                 \"  -  \",\"  R  \",\"  D  \",\"  !  \"]\n",
    "    \n",
    "print(\"Optimal policy:\")\n",
    "idxs = [0,4,8,12]\n",
    "for idx in idxs:\n",
    "    print(optimalPolicy[idx+0], optimalPolicy[idx+1], \n",
    "          optimalPolicy[idx+2], optimalPolicy[idx+3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()\n",
    "# env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q = np.ones((env.observation_space.n, env.action_space.n))\n",
    "# # Set q(terminal,*) equal to 0\n",
    "# q[5,:] = 0.0\n",
    "# q[7,:] = 0.0\n",
    "# q[11,:] = 0.0\n",
    "# q[12,:] = 0.0\n",
    "# q[15,:] = 0.0\n",
    "performance = np.zeros(episodes//STEPS) # np.ndarray(episodes//10)\n",
    "\n",
    "critic = np.random.uniform(low=0.0, high=0.0000000009, size=(env.observation_space.n, env.action_space.n))\n",
    "# critic = np.random.uniform(low=0.0, high=0.00000009, size=(env.observation_space.n, env.action_space.n))\n",
    "# v = np.random.rand(env.observation_space.n, env.action_space.n)\n",
    "\n",
    "actor = np.zeros((env.observation_space.n, env.action_space.n))\n",
    "# actor = np.random.uniform(low=0.0, high=0.0009, size=(env.observation_space.n, env.action_space.n))\n",
    "\n",
    "rng = np.random.default_rng() # random number generator\n",
    "policy_softmax = SoftmaxPolicy(env, rng)\n",
    "policy_greedy = GreedyPolicy(env)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for episode in range(episodes):\n",
    "\n",
    "    inew = min(episode,epsilon_annealing_stop)\n",
    "    epsilon = (epsilon_start * (epsilon_annealing_stop - inew) + epsilon_end * inew) / epsilon_annealing_stop\n",
    "    \n",
    "    E_actor = np.zeros((env.observation_space.n, env.action_space.n))\n",
    "    E_critic = np.zeros((env.observation_space.n, env.action_space.n))\n",
    "    \n",
    "    state = env.reset()\n",
    "    action = policy_softmax.action(actor, state, epsilon)\n",
    "    # action = action_epsilon_greedy(actor, state, epsilon)\n",
    "\n",
    "    while True:\n",
    "\n",
    "        (new_state, reward, done, truncated, info) = env.step(action)\n",
    "        \n",
    "        new_action = policy_softmax.action(actor, new_state, epsilon)\n",
    "        # new_action = action_epsilon_greedy(actor, new_state, epsilon)\n",
    "\n",
    "        E_actor[state, action] = 1\n",
    "        \n",
    "        td_error = reward + gamma * critic[new_state, new_action] - critic[state, new_action]\n",
    "\n",
    "        E_critic[state, action] = 1\n",
    "\n",
    "        critic = critic + alpha_critic * td_error * E_critic\n",
    "        E_critic = eligibility_decay * gamma * E_critic\n",
    "\n",
    "        actor = actor + alpha_actor * td_error * E_actor \n",
    "        E_actor = eligibility_decay * gamma * E_actor\n",
    "        \n",
    "        state, action = new_state, new_action\n",
    "\n",
    "        if done or truncated:\n",
    "\n",
    "            # if done:\n",
    "                # print(\"done in {} steps ({})\".format(env._elapsed_steps, episode))\n",
    "\n",
    "            break\n",
    "\n",
    "    # only for plotting the performance, not part of the algorithm \n",
    "    if episode%STEPS == 0:\n",
    "        # performance[episode//100] = average_performance(get_action_epsilon_greedy(epsilon), q=actor)\n",
    "        performance[episode//STEPS] = policy_greedy.average_performance(policy_greedy.action, q=actor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Average reward of an epoch')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(STEPS*np.arange(episodes//STEPS), performance)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.title(\"Learning progress for SARSA\")\n",
    "plt.ylabel(\"Average reward of an epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greedy policy SARSA performance = 1.0\n"
     ]
    }
   ],
   "source": [
    "greedyPolicyAvgPerf = policy_greedy.average_performance(policy_greedy.action, q=actor)\n",
    "print(\"Greedy policy SARSA performance =\", greedyPolicyAvgPerf) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(A,S) Value function = (256, 4)\n",
      "First row\n",
      "[[-0.  0.  0. -0.]\n",
      " [-0.  0.  0. -0.]\n",
      " [-0.  0.  0. -0.]\n",
      " [-0.  0.  0. -0.]]\n",
      "Second row\n",
      "[[-0.  0.  0. -0.]\n",
      " [-0.  0.  0. -0.]\n",
      " [-0.  0.  0. -0.]\n",
      " [-0.  0.  0.  0.]]\n",
      "Third row\n",
      "[[-0.  0.  0. -0.]\n",
      " [-0.  0.  0. -0.]\n",
      " [-0.  0.  0.  0.]\n",
      " [-0.  0.  0.  0.]]\n",
      "Fourth row\n",
      "[[-0.  0.  0.  0.]\n",
      " [-0.  0.  0.  0.]\n",
      " [-0.  0.  0.  0.]\n",
      " [-0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "q = actor\n",
    "q = np.round(q,3)\n",
    "print(\"(A,S) Value function =\", q.shape)\n",
    "print(\"First row\")\n",
    "print(q[0:4,:])\n",
    "print(\"Second row\")\n",
    "print(q[4:8,:])\n",
    "print(\"Third row\")\n",
    "print(q[8:12,:])\n",
    "print(\"Fourth row\")\n",
    "print(q[12:16,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greedy policy found:\n",
      "  L     L     L     L  \n",
      "  L     L     L     L  \n",
      "  L     L     L     L  \n",
      "  L     L     L     !  \n",
      " \n",
      "Optimal policy:\n",
      "L/D/R   U     U     U  \n",
      "  L     -    L/R    -  \n",
      "  U     D     L     -  \n",
      "  -     R     D     !  \n"
     ]
    }
   ],
   "source": [
    "policyFound = [actionsDict[np.argmax(q[0,:])],actionsDict[np.argmax(q[1,:])],actionsDict[np.argmax(q[2,:])],actionsDict[np.argmax(q[3,:])],\n",
    "               actionsDict[np.argmax(q[4,:])],actionsDict[np.argmax(q[5,:])],actionsDict[np.argmax(q[6,:])],actionsDict[np.argmax(q[6,:])],\n",
    "               actionsDict[np.argmax(q[8,:])],actionsDict[np.argmax(q[9,:])],actionsDict[np.argmax(q[10,:])],actionsDict[np.argmax(q[11,:])],\n",
    "               actionsDict[np.argmax(q[12,:])],actionsDict[np.argmax(q[13,:])],actionsDict[np.argmax(q[14,:])],\"  !  \"]\n",
    "print(\"Greedy policy found:\")\n",
    "idxs = [0,4,8,12]\n",
    "for idx in idxs:\n",
    "    print(policyFound[idx+0], policyFound[idx+1], \n",
    "          policyFound[idx+2], policyFound[idx+3])\n",
    "\n",
    "print(\" \")\n",
    "\n",
    "print(\"Optimal policy:\")\n",
    "idxs = [0,4,8,12]\n",
    "for idx in idxs:\n",
    "    print(optimalPolicy[idx+0], optimalPolicy[idx+1], \n",
    "          optimalPolicy[idx+2], optimalPolicy[idx+3])\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "4bd624a0593993fe43ac4046b27b898fb2ef75c21c08f81e89e64ea0f51df676"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
